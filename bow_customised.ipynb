{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e3d307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52e6acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: extracting face from the image.\n",
    "def face_detection(image):\n",
    "    # Read in the image\n",
    "    img = mpimg.imread(image)\n",
    "\n",
    "    # Detect the faces in image\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_img, scaleFactor = 1.3, minNeighbors = 5)\n",
    "    print(type(faces))\n",
    "    print(faces)\n",
    "\n",
    "    for x,y,w,h in faces:\n",
    "        img = cv2.rectangle(img, (x, y), (x+w, y+h), (255,0,0), 1)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    for x,y,w,h in faces:\n",
    "        extracted_img = img[y:y+h, x:x+w]\n",
    "        plt.imshow(extracted_img)\n",
    "        plt.show()\n",
    "\n",
    "    return extracted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18e19d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocessing and feature extraction\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14c62a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code of K-means from scratch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, k, max_iter=5, init_method=\"kmeans++\"):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "        self.inertia = np.inf\n",
    "        self.init_method = init_method\n",
    "\n",
    "    def init_centroids(self, X, num_centroids=None):\n",
    "        if self.init_method == \"forgy\":\n",
    "            self.init_forgy(X, num_centroids)\n",
    "        elif self.init_method == \"kmeans++\":\n",
    "            self.init_kmeans(X, num_centroids)\n",
    "\n",
    "    def init_forgy(self, X, num_centroids=None):\n",
    "        # \"Forgy\" initialization method\n",
    "        if num_centroids is None:\n",
    "            num_centroids = self.k\n",
    "        assert (\n",
    "            num_centroids <= X.shape[0]\n",
    "        ), \"Number of centroids must be less than number of data points\"\n",
    "        rand_indices = np.random.choice(X.shape[0], num_centroids, replace=False)\n",
    "        self.centroids = X[rand_indices]\n",
    "        print(self.centroids)\n",
    "\n",
    "    def init_kmeans(self, X, num_centroids=None):\n",
    "        # \"kmeans++\" initialization method\n",
    "        if num_centroids is None:\n",
    "            num_centroids = self.k\n",
    "        assert (\n",
    "            num_centroids <= X.shape[0]\n",
    "        ), \"Number of centroids must be less than number of data points\"\n",
    "        self.centroids = np.zeros((num_centroids, X.shape[1]))\n",
    "        self.centroids[0] = X[np.random.choice(X.shape[0], 1, replace=False)]\n",
    "        for i in range(1, num_centroids):\n",
    "            dists = np.linalg.norm(X - self.centroids[i - 1], axis=1)\n",
    "            probs = dists / np.sum(dists)\n",
    "            self.centroids[i] = X[\n",
    "                np.random.choice(X.shape[0], 1, replace=False, p=probs)\n",
    "            ]\n",
    "\n",
    "    def calc_inertia(self, X):\n",
    "        return sum(\n",
    "            np.linalg.norm(X[i] - self.centroids[int(self.labels[i])]) ** 2\n",
    "            for i in range(X.shape[0])\n",
    "        )\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.init_centroids(X)\n",
    "        self.labels = np.zeros(X.shape[0])\n",
    "        self.iter = 0\n",
    "        print(\"-\" * 80)\n",
    "        print(\"Initial inertia: \", self.calc_inertia(X))\n",
    "\n",
    "        # Convergence criteria 1: Number of iterations is less than max_iter\n",
    "        while self.iter < self.max_iter:\n",
    "\n",
    "            # Assignment step for each data point\n",
    "            for i in range(X.shape[0]):\n",
    "                self.labels[i] = np.argmin(\n",
    "                    np.linalg.norm(X[i] - self.centroids, axis=1)\n",
    "                )\n",
    "\n",
    "            # Update step for each centroid\n",
    "            for i in range(self.k):\n",
    "                self.centroids[i] = np.mean(X[self.labels == i], axis=0)\n",
    "\n",
    "            self.iter += 1\n",
    "\n",
    "            # Convergence criteria 2: Inertia should be less than previous inertia\n",
    "            if self.calc_inertia(X) >= self.inertia:\n",
    "                break\n",
    "\n",
    "            self.inertia = self.calc_inertia(X)\n",
    "            self.metric1 = davies_bouldin_score(X, self.labels)\n",
    "            self.metric2 = silhouette_score(X, self.labels)\n",
    "            print(\"-\" * 80)\n",
    "            print(\"Iteration: \", self.iter)\n",
    "            print(\"Inertia: \", self.inertia)\n",
    "            print(\"Sklearn metrics : \")\n",
    "            print(\"Silhouette score: \", self.metric2)\n",
    "            print(\"Davies-Bouldin score: \", self.metric1)\n",
    "\n",
    "        # Calculate inertia and homogeneous after convergence\n",
    "        self.inertia = self.calc_inertia(X)\n",
    "        self.metric1 = davies_bouldin_score(X, self.labels)\n",
    "        self.metric2 = silhouette_score(X, self.labels)\n",
    "        print(\"-\" * 80)\n",
    "        print(\"Final inertia: \", self.inertia)\n",
    "        print(\"Sklearn metrics : \")\n",
    "        print(\"Silhouette score: \", self.metric2)\n",
    "        print(\"Davies-Bouldin score: \", self.metric1)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # return the labels for each data point in X\n",
    "        labels = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            labels[i] = np.argmin(np.linalg.norm(X[i] - self.centroids, axis=1))\n",
    "        labels = [int(label + 1) for label in labels]\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4cdb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clustering\n",
    "def cluster_features(features, num_clusters):\n",
    "    features_array = np.concatenate(features)  # Convert list of arrays to a single NumPy array\n",
    "    kmeans = KMeans(k=num_clusters)\n",
    "    kmeans.fit(features_array.astype('float32'))  # Convert features to float32\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f411e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Assigning visual words\n",
    "def assign_visual_words(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    visual_words_hist, _ = np.histogram(visual_words, bins=range(kmeans.n_clusters + 1), density=True)\n",
    "    return visual_words_hist.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e43e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Encoding\n",
    "def encode_image(image_path, kmeans):\n",
    "    features = preprocess_image(image_path)\n",
    "    if features is not None:\n",
    "        visual_words = assign_visual_words(features, kmeans)\n",
    "        return visual_words\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e449ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Training\n",
    "def train_svm(train_data, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_data, train_labels)\n",
    "    return svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a33d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 7: classification\n",
    "def classify_image(image_path, svm, kmeans):\n",
    "    encoded_image = encode_image(image_path, kmeans)\n",
    "    if encoded_image is not None:\n",
    "        label = svm.predict([encoded_image])\n",
    "        return label[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91b0bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images/train/angry', 'images/train/happy', 'images/train/sad', 'images/train/surprise']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "# Train a classifier using the training dataset\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "classes = sorted(glob.glob(\"images/train/*\"))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c27d7ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Initial inertia:  29961750638.0\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration:  1\n",
      "Inertia:  9959530377.667269\n",
      "Sklearn metrics : \n",
      "Silhouette score:  0.013066542\n",
      "Davies-Bouldin score:  3.5593630570050085\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration:  2\n",
      "Inertia:  9436754858.903145\n",
      "Sklearn metrics : \n",
      "Silhouette score:  0.026699942\n",
      "Davies-Bouldin score:  3.379272787812208\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration:  3\n",
      "Inertia:  9287008675.207102\n",
      "Sklearn metrics : \n",
      "Silhouette score:  0.028982399\n",
      "Davies-Bouldin score:  3.2770824536870857\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration:  4\n",
      "Inertia:  9212625051.82595\n",
      "Sklearn metrics : \n",
      "Silhouette score:  0.029852621\n",
      "Davies-Bouldin score:  3.2160382446753233\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration:  5\n",
      "Inertia:  9166570332.926302\n",
      "Sklearn metrics : \n",
      "Silhouette score:  0.030339327\n",
      "Davies-Bouldin score:  3.176079016763764\n",
      "--------------------------------------------------------------------------------\n",
      "Final inertia:  9166570332.926302\n",
      "Sklearn metrics : \n",
      "Silhouette score:  0.030339327\n",
      "Davies-Bouldin score:  3.176079016763764\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'KMeans' object has no attribute 'n_clusters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-796d525748c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;31m# Encode each image using the K-means clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mencoded_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mencoded_image\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;31m# Append the encoded image and its label to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-b035d0b5fdf6>\u001b[0m in \u001b[0;36mencode_image\u001b[0;34m(image_path, kmeans)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mvisual_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_visual_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisual_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-9947b92b31b1>\u001b[0m in \u001b[0;36massign_visual_words\u001b[0;34m(features, kmeans)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0massign_visual_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvisual_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvisual_words_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvisual_words_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KMeans' object has no attribute 'n_clusters'"
     ]
    }
   ],
   "source": [
    "for i in range(len(classes)):\n",
    "    if i == 0:\n",
    "        # Get the list of image paths for the current class\n",
    "        class_images = glob.glob(classes[i] + \"/*.jpg\")\n",
    "        num_images_per_class = len(class_images)\n",
    "\n",
    "        features = []\n",
    "        for j in range(num_images_per_class):\n",
    "            # Process each image and extract its descriptors\n",
    "            image_path = class_images[j]\n",
    "            descriptors = preprocess_image(image_path)\n",
    "            if descriptors is not None:\n",
    "                features.append(descriptors)\n",
    "\n",
    "        if len(features) > 0:\n",
    "            # Cluster the extracted features using K-means\n",
    "            kmeans = cluster_features(features, num_clusters=100)\n",
    "            for j in range(num_images_per_class):\n",
    "                # Encode each image using the K-means clusters\n",
    "                image_path = class_images[j]\n",
    "                encoded_image = encode_image(image_path, kmeans)\n",
    "                if encoded_image is not None:\n",
    "                    # Append the encoded image and its label to the training data\n",
    "                    train_data.append(encoded_image.astype('float32'))  # Convert encoded_image to float32\n",
    "                    train_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53febd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5368383",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = train_svm(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_face = face_detection('sad.jpg')\n",
    "filename = \"face.jpg\"\n",
    "cv2.imwrite(filename, extracted_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de162c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = \"face.jpg\"\n",
    "predicted_label = classify_image(test_image_path, svm, kmeans)\n",
    "if predicted_label is not None:\n",
    "    print(\"Predicted label:\", predicted_label)\n",
    "else:\n",
    "    print(\"Unable to classify the image.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
